{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b0cc68-ad8e-4e66-97a8-81182121cc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.19.0.6 172.18.0.5 172.20.0.2 \n"
     ]
    }
   ],
   "source": [
    "!hostname -I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc6fe573-a22c-40a8-8327-664ab3247ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82ec78d4-9724-401e-b142-a94b23e0b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdfs import InsecureClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fce77bb-f0da-4979-b89e-0e670175fbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                 Apache License\n",
      "                           Version 2.0, January 2004\n",
      "                        http://www.apache.org/licenses/\n",
      "\n",
      "   TERMS AND CONDITIONS FOR USE, REPRODUC\n"
     ]
    }
   ],
   "source": [
    "user = \"hadoop\"\n",
    "host = \"http://namenode:9870\"\n",
    "path = \"/user/hadoop/LICENSE.txt\"\n",
    "hdfs = InsecureClient(host, user)\n",
    "with hdfs.read(path, encoding='utf-8') as reader:\n",
    "    text = reader.read()\n",
    "print(text[:200])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e598234-5851-4284-acb2-4270f6afe160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache     1\n",
      "License     1\n",
      "Version     1\n",
      "2.0,     1\n",
      "January     1\n",
      "2004     1\n",
      "http://www.apache.org/licenses/     1\n",
      "TERMS     1\n",
      "AND     1\n",
      "CONDITIONS     1\n",
      "FOR     1\n",
      "USE,     1\n",
      "REPRODUC     1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    " \n",
    "words = text[:200].strip().split()\n",
    "word_counts = Counter(words)\n",
    "# print(word_counts)\n",
    "for word, count in word_counts.items():\n",
    "    print(word,\"   \",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74c32b17-8946-40cb-a1f9-20d533087a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부산광역시구분별사업체수종사자수_2020.csv\n",
      "LICENSE.txt\n",
      "starbucks_20250411113937.csv\n"
     ]
    }
   ],
   "source": [
    "# 경로내 파일 읽어오기\n",
    "hdfs_dir ='/user/hadoop'\n",
    "show = hdfs.list(hdfs_dir)\n",
    "for s in show:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e1d3341-855f-4bbe-b816-5550c60c5502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pkdata/data/python/빅데이터 분석\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4ecb314-80e5-463c-a7e6-a890ebf1bdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "업로드 완료\n"
     ]
    }
   ],
   "source": [
    "# 파일 업로드\n",
    "local_path = './ref/starbucks_20250411113937.csv'\n",
    "hdfs_path = '/user/hadoop/starbucks2.csv'\n",
    "hdfs.upload(hdfs_path, local_path, overwrite = True )\n",
    "print(\"업로드 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c09d0fb-e837-425f-a2a2-9d3169c419da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accessTime': 0, 'blockSize': 0, 'childrenNum': 4, 'fileId': 16387, 'group': 'supergroup', 'length': 0, 'modificationTime': 1744780109322, 'owner': 'hadoop', 'pathSuffix': '', 'permission': '777', 'replication': 0, 'storagePolicy': 0, 'type': 'DIRECTORY'}\n"
     ]
    }
   ],
   "source": [
    "# 파일 확인\n",
    "hdfs_path = '/user/hadoop/'\n",
    "file_name = 'starbucks2.csv'\n",
    "check = hdfs_path + file_name\n",
    "if hdfs.status(check, strict=False) == None:\n",
    "    print(f\"{check}의 파일이 없습니다.\")\n",
    "else:\n",
    "    print(hdfs.status(hdfs_path, strict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "628bd9e5-a1b2-4fa3-b0fb-a39aa63225e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제되었습니다.\n"
     ]
    }
   ],
   "source": [
    "hdfs_path = '/user/hadoop/'\n",
    "del_file = 'starbucks2.csv'\n",
    "full_path = hdfs_path + del_file\n",
    "if hdfs.delete(full_path):\n",
    "    print(\"삭제되었습니다.\")\n",
    "else:\n",
    "    if hdfs.status(full_path, strict=False) == None:\n",
    "        print(f\"{full_path}의 파일이 없습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
